{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Analisis del los datos de Ofertas por Jornada en el contexto AA (Aprendizaje Autom치tico)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Importaci칩n de las bibliotecas de AA en Python"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.decomposition import PCA\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn import preprocessing\n",
    "import datetime\n",
    "import uuid\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Cargar los datos para evaluar correlaciones"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load the csv data sets\n",
    "csv_dataset = pd.read_csv(\"train/train-offers-dataset.csv\")\n",
    "\n",
    "# create a Panda DataFramce\n",
    "df_dataset = pd.DataFrame(csv_dataset)\n",
    "\n",
    "# print the first few rows to make sure that data has been loaded as expected\n",
    "df_dataset.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Inspecti칩n de los tipos de Datos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_dataset.dtypes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Descripci칩n del DataFrame"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_dataset.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Quitar las funciones que no aportan valor al modelo y normalizar los datos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# drop featuresd with low occurance/correlation\n",
    "\n",
    "# drop the labels from the dataset\n",
    "df_dataset_pca = pd.DataFrame(csv_dataset).drop(['phase1prediction','phase2prediction','phase3prediction','phase4prediction'], axis = 1)\n",
    "df_dataset_pca.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Visualizar el Variance Ratio entre las functiones "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pca = PCA().fit(df_dataset_pca)\n",
    "plt.plot(np.cumsum(pca.explained_variance_ratio_))\n",
    "plt.xlabel('numero de funciones')\n",
    "plt.ylabel('cumulative explained variance');"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Visualizar un PairPlot del modelo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "jet= plt.get_cmap('jet')\n",
    "\n",
    "def generate_pairplot(df, variables, predictor_name, phase_name, n_rows, n_cols):\n",
    "    print(\"\\n\")\n",
    "    print(f\"Correlacion de funciones en {phase_name}\")\n",
    "    print(\"\\n\")\n",
    "    fig = plt.figure(figsize=(22,20))\n",
    "    for i, var in enumerate(variables):\n",
    "        ax = fig.add_subplot(n_rows,n_cols,i+1)\n",
    "        asset = df.loc[:,var]\n",
    "        ax.scatter(df[predictor_name], asset)\n",
    "        ax.set_xlabel(predictor_name)\n",
    "        ax.set_ylabel(\"{}\".format(var))\n",
    "        ax.set_title(f\"{var} vs {predictor_name}\")\n",
    "    fig.tight_layout() \n",
    "    plt.show()\n",
    "\n",
    "# normalize the magnitude of the dataset\n",
    "df_dataset_scaler = preprocessing.MinMaxScaler()\n",
    "df_dataset_scaled = pd.DataFrame(df_dataset_scaler.fit_transform(df_dataset), columns = ['greenfield','vpc', 'subnets', 'connectivity', 'peerings', 'directoryservice', 'otherservices', 'advsecurity', 'advlogging', 'advmonitoring', 'advbackup', 'vms', 'buckets', 'databases', 'elb', 'autoscripts', 'administered', 'phase1prediction', 'phase2prediction', 'phase3prediction', 'phase4prediction'])\n",
    "\n",
    "df_dataset_phase1 = df_dataset_scaled.drop(['phase2prediction', 'phase3prediction', 'phase4prediction'], axis = 1)\n",
    "df_dataset_phase2 = df_dataset_scaled.drop(['phase3prediction', 'phase4prediction'], axis = 1)\n",
    "df_dataset_phase3 = df_dataset_scaled.drop(['phase4prediction'], axis = 1)\n",
    "df_dataset_phase4 = df_dataset_scaled.copy()\n",
    "\n",
    "# generate_pairplot(df_dataset_phase1, df_dataset_phase1.columns, \"phase1prediction\", \"Phase 1: Recopilacion\", 5, 4)\n",
    "# generate_pairplot(df_dataset_phase2, df_dataset_phase2.columns, \"phase2prediction\", \"Phase 2: Diseno\", 5, 4)\n",
    "# generate_pairplot(df_dataset_phase3, df_dataset_phase3.columns, \"phase3prediction\", \"Phase 3: Implantacion\", 5, 4)\n",
    "generate_pairplot(df_dataset_phase4, df_dataset_phase4.columns, \"phase4prediction\", \"Todas las fases\", 5, 5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Calcular el Covariance Matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_covariance_matrix_graph(df, cmap_color, phase_name):\n",
    "    # plot the covariance matrix\n",
    "    corr = df.corr()\n",
    "    # figsize in inches\n",
    "    fig, ax = plt.subplots(figsize=(20,20))\n",
    "    ax.set_title(phase_name)\n",
    "    sns.heatmap(corr, annot = True, square=True, fmt='.2g', vmin=-1, vmax=1, center= 0, cmap= cmap_color, linewidths=3, linecolor='black', ax=ax)\n",
    "\n",
    "    \n",
    "# generate_covariance_matrix_graph(df_dataset_phase1, \"coolwarm\", \"Phase 1: Recopilacion\")\n",
    "# generate_covariance_matrix_graph(df_dataset_phase2, \"BrBG_r\", \"Phase 2: Diseno\")\n",
    "# generate_covariance_matrix_graph(df_dataset_phase3, \"gist_rainbow_r\", \"Phase 3: Implantacion\")\n",
    "generate_covariance_matrix_graph(df_dataset_phase4, \"twilight_shifted_r\", \"Phase 4: Soporte\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Covariance matrix en formato tabular"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# uuid for the evaluation run\n",
    "eval_id = uuid.uuid4()\n",
    "\n",
    "# datetime of the evaluation run\n",
    "now = datetime.datetime.now().strftime(\"%Y-%m-%d %H:%M:%S\")\n",
    "\n",
    "corr_data_frames_arr = []\n",
    "\n",
    "\n",
    "def generate_covariance_matrix_table(df, phase_name, phase_predictor):\n",
    "    corr_df = df.corr(method='pearson', min_periods=10)[phase_predictor]\n",
    "    corr_data_frames_arr.append(pd.DataFrame(corr_df).T)\n",
    "    \n",
    "\n",
    "generate_covariance_matrix_table(df_dataset_phase1, \"Phase 1: Recopilacion\", \"phase1prediction\")\n",
    "generate_covariance_matrix_table(df_dataset_phase2, \"Phase 2: Diseno\", \"phase2prediction\")\n",
    "generate_covariance_matrix_table(df_dataset_phase3, \"Phase 3: Implantacion\", \"phase3prediction\")\n",
    "generate_covariance_matrix_table(df_dataset_phase4, \"Phase 4: Soporte\", \"phase4prediction\")\n",
    "\n",
    "corr_data_frame = pd.DataFrame(pd.concat(corr_data_frames_arr))\n",
    "corr_data_frame.insert(0, 'evaluation_id', eval_id)\n",
    "corr_data_frame.insert(1, 'datetime', now)\n",
    "\n",
    "with open(f\"analysis/dataset/covariance-matrix.csv\", \"a+\") as csv_file:\n",
    "    corr_data_frame.to_csv(csv_file, header=False, index=False)\n",
    "    \n",
    "print(\"\\n\")\n",
    "print(f\"Evaluatiuon id: {eval_id}\")\n",
    "print(\"\\n\")\n",
    "corr_data_frame.head()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
