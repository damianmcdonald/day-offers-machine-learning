{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Predicciones de jornadas de fases con AA (Aprendizaje Automático)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Familia de algoritmos: <code>XGBoost</code>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Importación de las bibliotecas de AA en Python"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting package metadata (current_repodata.json): done\n",
      "Solving environment: done\n",
      "\n",
      "\n",
      "==> WARNING: A newer version of conda exists. <==\n",
      "  current version: 4.8.2\n",
      "  latest version: 4.8.3\n",
      "\n",
      "Please update conda by running\n",
      "\n",
      "    $ conda update -n base conda\n",
      "\n",
      "\n",
      "\n",
      "## Package Plan ##\n",
      "\n",
      "  environment location: /opt/conda\n",
      "\n",
      "  added / updated specs:\n",
      "    - graphviz\n",
      "    - mscorefonts\n",
      "    - prettytable\n",
      "    - python-graphviz\n",
      "    - xgboost\n",
      "\n",
      "\n",
      "The following packages will be downloaded:\n",
      "\n",
      "    package                    |            build\n",
      "    ---------------------------|-----------------\n",
      "    _py-xgboost-mutex-2.0      |            cpu_0           8 KB  conda-forge\n",
      "    ca-certificates-2020.6.20  |       hecda079_0         145 KB  conda-forge\n",
      "    cairo-1.16.0               |    hcf35c78_1003         1.5 MB  conda-forge\n",
      "    certifi-2020.6.20          |   py37hc8dfbb8_0         151 KB  conda-forge\n",
      "    expat-2.2.9                |       he1b5a44_2         191 KB  conda-forge\n",
      "    fontconfig-2.13.1          |    h86ecdb6_1001         340 KB  conda-forge\n",
      "    fribidi-1.0.9              |       h516909a_0         113 KB  conda-forge\n",
      "    gettext-0.19.8.1           |    hc5be6a0_1002         3.6 MB  conda-forge\n",
      "    glib-2.65.0                |       h6f030ca_0         3.5 MB  conda-forge\n",
      "    graphite2-1.3.13           |    he1b5a44_1001         102 KB  conda-forge\n",
      "    graphviz-2.42.3            |       h0511662_0         6.9 MB  conda-forge\n",
      "    harfbuzz-2.4.0             |       h9f30f68_3         1.5 MB  conda-forge\n",
      "    libiconv-1.15              |    h516909a_1006         2.0 MB  conda-forge\n",
      "    libtool-2.4.6              |    h14c3975_1002         512 KB  conda-forge\n",
      "    libuuid-2.32.1             |    h14c3975_1000          26 KB  conda-forge\n",
      "    libxcb-1.13                |    h14c3975_1002         396 KB  conda-forge\n",
      "    libxgboost-1.0.2           |       he1b5a44_1         2.8 MB  conda-forge\n",
      "    libxml2-2.9.10             |       hee79883_0         1.3 MB  conda-forge\n",
      "    mscorefonts-0.0.1          |                3         3.1 MB  conda-forge\n",
      "    pango-1.42.4               |       h7062337_4         521 KB  conda-forge\n",
      "    pcre-8.44                  |       he1b5a44_0         261 KB  conda-forge\n",
      "    pixman-0.38.0              |    h516909a_1003         594 KB  conda-forge\n",
      "    prettytable-0.7.2          |             py_3          15 KB  conda-forge\n",
      "    pthread-stubs-0.4          |    h14c3975_1001           5 KB  conda-forge\n",
      "    py-xgboost-1.0.2           |   py37hc8dfbb8_1         2.2 MB  conda-forge\n",
      "    python-graphviz-0.14       |     pyh9f0ad1d_0          19 KB  conda-forge\n",
      "    xgboost-1.0.2              |   py37h3340039_1          11 KB  conda-forge\n",
      "    xorg-kbproto-1.0.7         |    h14c3975_1002          26 KB  conda-forge\n",
      "    xorg-libice-1.0.10         |       h516909a_0          57 KB  conda-forge\n",
      "    xorg-libsm-1.2.3           |    h84519dc_1000          25 KB  conda-forge\n",
      "    xorg-libx11-1.6.9          |       h516909a_0         918 KB  conda-forge\n",
      "    xorg-libxau-1.0.9          |       h14c3975_0          13 KB  conda-forge\n",
      "    xorg-libxdmcp-1.1.3        |       h516909a_0          18 KB  conda-forge\n",
      "    xorg-libxext-1.3.4         |       h516909a_0          51 KB  conda-forge\n",
      "    xorg-libxpm-3.5.13         |       h516909a_0          63 KB  conda-forge\n",
      "    xorg-libxrender-0.9.10     |    h516909a_1002          31 KB  conda-forge\n",
      "    xorg-libxt-1.1.5           |    h516909a_1003         367 KB  conda-forge\n",
      "    xorg-renderproto-0.11.1    |    h14c3975_1002           8 KB  conda-forge\n",
      "    xorg-xextproto-7.3.0       |    h14c3975_1002          27 KB  conda-forge\n",
      "    xorg-xproto-7.0.31         |    h14c3975_1007          72 KB  conda-forge\n",
      "    ------------------------------------------------------------\n",
      "                                           Total:        33.4 MB\n",
      "\n",
      "The following NEW packages will be INSTALLED:\n",
      "\n",
      "  _py-xgboost-mutex  conda-forge/linux-64::_py-xgboost-mutex-2.0-cpu_0\n",
      "  cairo              conda-forge/linux-64::cairo-1.16.0-hcf35c78_1003\n",
      "  expat              conda-forge/linux-64::expat-2.2.9-he1b5a44_2\n",
      "  fontconfig         conda-forge/linux-64::fontconfig-2.13.1-h86ecdb6_1001\n",
      "  fribidi            conda-forge/linux-64::fribidi-1.0.9-h516909a_0\n",
      "  gettext            conda-forge/linux-64::gettext-0.19.8.1-hc5be6a0_1002\n",
      "  glib               conda-forge/linux-64::glib-2.65.0-h6f030ca_0\n",
      "  graphite2          conda-forge/linux-64::graphite2-1.3.13-he1b5a44_1001\n",
      "  graphviz           conda-forge/linux-64::graphviz-2.42.3-h0511662_0\n",
      "  harfbuzz           conda-forge/linux-64::harfbuzz-2.4.0-h9f30f68_3\n",
      "  libiconv           conda-forge/linux-64::libiconv-1.15-h516909a_1006\n",
      "  libtool            conda-forge/linux-64::libtool-2.4.6-h14c3975_1002\n",
      "  libuuid            conda-forge/linux-64::libuuid-2.32.1-h14c3975_1000\n",
      "  libxcb             conda-forge/linux-64::libxcb-1.13-h14c3975_1002\n",
      "  libxgboost         conda-forge/linux-64::libxgboost-1.0.2-he1b5a44_1\n",
      "  libxml2            conda-forge/linux-64::libxml2-2.9.10-hee79883_0\n",
      "  mscorefonts        conda-forge/noarch::mscorefonts-0.0.1-3\n",
      "  pango              conda-forge/linux-64::pango-1.42.4-h7062337_4\n",
      "  pcre               conda-forge/linux-64::pcre-8.44-he1b5a44_0\n",
      "  pixman             conda-forge/linux-64::pixman-0.38.0-h516909a_1003\n",
      "  prettytable        conda-forge/noarch::prettytable-0.7.2-py_3\n",
      "  pthread-stubs      conda-forge/linux-64::pthread-stubs-0.4-h14c3975_1001\n",
      "  py-xgboost         conda-forge/linux-64::py-xgboost-1.0.2-py37hc8dfbb8_1\n",
      "  python-graphviz    conda-forge/noarch::python-graphviz-0.14-pyh9f0ad1d_0\n",
      "  xgboost            conda-forge/linux-64::xgboost-1.0.2-py37h3340039_1\n",
      "  xorg-kbproto       conda-forge/linux-64::xorg-kbproto-1.0.7-h14c3975_1002\n",
      "  xorg-libice        conda-forge/linux-64::xorg-libice-1.0.10-h516909a_0\n",
      "  xorg-libsm         conda-forge/linux-64::xorg-libsm-1.2.3-h84519dc_1000\n",
      "  xorg-libx11        conda-forge/linux-64::xorg-libx11-1.6.9-h516909a_0\n",
      "  xorg-libxau        conda-forge/linux-64::xorg-libxau-1.0.9-h14c3975_0\n",
      "  xorg-libxdmcp      conda-forge/linux-64::xorg-libxdmcp-1.1.3-h516909a_0\n",
      "  xorg-libxext       conda-forge/linux-64::xorg-libxext-1.3.4-h516909a_0\n",
      "  xorg-libxpm        conda-forge/linux-64::xorg-libxpm-3.5.13-h516909a_0\n",
      "  xorg-libxrender    conda-forge/linux-64::xorg-libxrender-0.9.10-h516909a_1002\n",
      "  xorg-libxt         conda-forge/linux-64::xorg-libxt-1.1.5-h516909a_1003\n",
      "  xorg-renderproto   conda-forge/linux-64::xorg-renderproto-0.11.1-h14c3975_1002\n",
      "  xorg-xextproto     conda-forge/linux-64::xorg-xextproto-7.3.0-h14c3975_1002\n",
      "  xorg-xproto        conda-forge/linux-64::xorg-xproto-7.0.31-h14c3975_1007\n",
      "\n",
      "The following packages will be UPDATED:\n",
      "\n",
      "  ca-certificates                     2020.4.5.1-hecc5488_0 --> 2020.6.20-hecda079_0\n",
      "  certifi                         2020.4.5.1-py37hc8dfbb8_0 --> 2020.6.20-py37hc8dfbb8_0\n",
      "\n",
      "\n",
      "\n",
      "Downloading and Extracting Packages\n",
      "xorg-libxext-1.3.4   | 51 KB     | ##################################### | 100% \n",
      "xorg-libxrender-0.9. | 31 KB     | ##################################### | 100% \n",
      "libxgboost-1.0.2     | 2.8 MB    | ##################################### | 100% \n",
      "pango-1.42.4         | 521 KB    | ##################################### | 100% \n",
      "xorg-libice-1.0.10   | 57 KB     | ##################################### | 100% \n",
      "fribidi-1.0.9        | 113 KB    | ##################################### | 100% \n",
      "xorg-xproto-7.0.31   | 72 KB     | ##################################### | 100% \n",
      "xorg-libxt-1.1.5     | 367 KB    | ##################################### | 100% \n",
      "xorg-libx11-1.6.9    | 918 KB    | ##################################### | 100% \n",
      "xorg-libxau-1.0.9    | 13 KB     | ##################################### | 100% \n",
      "_py-xgboost-mutex-2. | 8 KB      | ##################################### | 100% \n",
      "harfbuzz-2.4.0       | 1.5 MB    | ##################################### | 100% \n",
      "xorg-libsm-1.2.3     | 25 KB     | ##################################### | 100% \n",
      "prettytable-0.7.2    | 15 KB     | ##################################### | 100% \n",
      "libuuid-2.32.1       | 26 KB     | ##################################### | 100% \n",
      "xorg-kbproto-1.0.7   | 26 KB     | ##################################### | 100% \n",
      "fontconfig-2.13.1    | 340 KB    | ##################################### | 100% \n",
      "cairo-1.16.0         | 1.5 MB    | ##################################### | 100% \n",
      "xorg-renderproto-0.1 | 8 KB      | ##################################### | 100% \n",
      "glib-2.65.0          | 3.5 MB    | ##################################### | 100% \n",
      "libtool-2.4.6        | 512 KB    | ##################################### | 100% \n",
      "xgboost-1.0.2        | 11 KB     | ##################################### | 100% \n",
      "libxml2-2.9.10       | 1.3 MB    | ##################################### | 100% \n",
      "xorg-libxpm-3.5.13   | 63 KB     | ##################################### | 100% \n",
      "certifi-2020.6.20    | 151 KB    | ##################################### | 100% \n",
      "pthread-stubs-0.4    | 5 KB      | ##################################### | 100% \n",
      "xorg-xextproto-7.3.0 | 27 KB     | ##################################### | 100% \n",
      "ca-certificates-2020 | 145 KB    | ##################################### | 100% \n",
      "pcre-8.44            | 261 KB    | ##################################### | 100% \n",
      "xorg-libxdmcp-1.1.3  | 18 KB     | ##################################### | 100% \n",
      "gettext-0.19.8.1     | 3.6 MB    | ##################################### | 100% \n",
      "libxcb-1.13          | 396 KB    | ##################################### | 100% \n",
      "graphviz-2.42.3      | 6.9 MB    | ##################################### | 100% \n",
      "mscorefonts-0.0.1    | 3.1 MB    | ##################################### | 100% \n",
      "libiconv-1.15        | 2.0 MB    | ##################################### | 100% \n",
      "graphite2-1.3.13     | 102 KB    | ##################################### | 100% \n",
      "python-graphviz-0.14 | 19 KB     | ##################################### | 100% \n",
      "pixman-0.38.0        | 594 KB    | ##################################### | 100% \n",
      "py-xgboost-1.0.2     | 2.2 MB    | ##################################### | 100% \n",
      "expat-2.2.9          | 191 KB    | ##################################### | 100% \n",
      "Preparing transaction: done\n",
      "Verifying transaction: done\n",
      "Executing transaction: done\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np \n",
    "from scipy.stats import uniform, randint\n",
    "from sklearn.metrics import auc, accuracy_score, confusion_matrix, mean_squared_error\n",
    "from sklearn import model_selection\n",
    "from sklearn.model_selection import cross_val_score, GridSearchCV, KFold, RandomizedSearchCV, train_test_split\n",
    "from sklearn.utils import shuffle\n",
    "import matplotlib.pyplot as plt\n",
    "import datetime\n",
    "import uuid\n",
    "import math\n",
    "import sys\n",
    "import csv\n",
    "import sqlite3\n",
    "import json\n",
    "!conda install --yes --prefix {sys.prefix} prettytable xgboost graphviz python-graphviz mscorefonts\n",
    "import xgboost as xgb\n",
    "from prettytable import PrettyTable\n",
    "import matplotlib.font_manager as font_manager\n",
    "font_manager._rebuild()\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Helper functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "PATIENCE_THRESHOLD = 10\n",
    "EPOCHS = 1000\n",
    "\n",
    "def display_scores(scores):\n",
    "    print(\"Scores: {0}\\nMean: {1:.3f}\\nStd: {2:.3f}\".format(scores, np.mean(scores), np.std(scores)))\n",
    "    \n",
    "\n",
    "def report_best_scores(results, n_top=3):\n",
    "    for i in range(1, n_top + 1):\n",
    "        candidates = np.flatnonzero(results['rank_test_score'] == i)\n",
    "        for candidate in candidates:\n",
    "            print(\"Model with rank: {0}\".format(i))\n",
    "            print(\"Mean validation score: {0:.3f} (std: {1:.3f})\".format(\n",
    "                  results['mean_test_score'][candidate],\n",
    "                  results['std_test_score'][candidate]))\n",
    "            print(\"Parameters\")\n",
    "            print(json.dumps(results['params'][candidate], indent=4, sort_keys=True))\n",
    "            print(\"\")\n",
    "            \n",
    "            \n",
    "def get_min_value(predicted_value, phase_number):\n",
    "    \n",
    "    \n",
    "    def min_phase_val(i):\n",
    "        switcher = {\n",
    "                1: 0.75,\n",
    "                2: 1.5,\n",
    "                3: 2,\n",
    "                4: 0.25\n",
    "             }\n",
    "        return switcher.get(i,f\"Invalid phase:{i}\")\n",
    "\n",
    "\n",
    "    rounded_val = round((float(predicted_value)*4))/4\n",
    "    if rounded_val > 0 and rounded_val > min_phase_val(phase_number):\n",
    "        return rounded_val\n",
    "             \n",
    "    return min_phase_val(phase_number)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Cargar los datos para entreñar y testar el modelo de AA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>greenfield</th>\n",
       "      <th>vpc</th>\n",
       "      <th>subnets</th>\n",
       "      <th>connectivity</th>\n",
       "      <th>peerings</th>\n",
       "      <th>directoryservice</th>\n",
       "      <th>otherservices</th>\n",
       "      <th>advsecurity</th>\n",
       "      <th>advlogging</th>\n",
       "      <th>advmonitoring</th>\n",
       "      <th>...</th>\n",
       "      <th>vms</th>\n",
       "      <th>buckets</th>\n",
       "      <th>databases</th>\n",
       "      <th>elb</th>\n",
       "      <th>autoscripts</th>\n",
       "      <th>administered</th>\n",
       "      <th>phase1prediction</th>\n",
       "      <th>phase2prediction</th>\n",
       "      <th>phase3prediction</th>\n",
       "      <th>phase4prediction</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.75</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>0.8</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>3.50</td>\n",
       "      <td>5.50</td>\n",
       "      <td>5.50</td>\n",
       "      <td>3.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.75</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>0.8</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>3.50</td>\n",
       "      <td>5.50</td>\n",
       "      <td>5.50</td>\n",
       "      <td>3.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.75</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.6</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>3.00</td>\n",
       "      <td>4.75</td>\n",
       "      <td>4.75</td>\n",
       "      <td>2.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.50</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.5</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1.75</td>\n",
       "      <td>2.75</td>\n",
       "      <td>2.75</td>\n",
       "      <td>1.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.75</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.6</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>3.00</td>\n",
       "      <td>4.75</td>\n",
       "      <td>4.75</td>\n",
       "      <td>2.5</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 21 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   greenfield  vpc  subnets  connectivity  peerings  directoryservice  \\\n",
       "0           1  1.0     0.75             0         1                 1   \n",
       "1           1  1.0     0.75             0         1                 1   \n",
       "2           0  0.5     0.75             0         0                 0   \n",
       "3           1  0.5     0.50             0         1                 0   \n",
       "4           0  0.5     0.75             0         0                 0   \n",
       "\n",
       "   otherservices  advsecurity  advlogging  advmonitoring  ...  vms  buckets  \\\n",
       "0            1.0            1           0              1  ...  0.8      0.0   \n",
       "1            1.0            1           0              1  ...  0.8      0.0   \n",
       "2            1.0            1           1              0  ...  0.6      1.0   \n",
       "3            1.0            1           0              0  ...  0.0      0.0   \n",
       "4            1.0            1           1              0  ...  0.6      1.0   \n",
       "\n",
       "   databases  elb  autoscripts  administered  phase1prediction  \\\n",
       "0        1.0    0            1             0              3.50   \n",
       "1        1.0    0            1             1              3.50   \n",
       "2        1.0    0            1             0              3.00   \n",
       "3        0.5    1            1             0              1.75   \n",
       "4        1.0    0            1             1              3.00   \n",
       "\n",
       "   phase2prediction  phase3prediction  phase4prediction  \n",
       "0              5.50              5.50               3.0  \n",
       "1              5.50              5.50               3.0  \n",
       "2              4.75              4.75               2.5  \n",
       "3              2.75              2.75               1.5  \n",
       "4              4.75              4.75               2.5  \n",
       "\n",
       "[5 rows x 21 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# load the csv data sets\n",
    "csv_dataset = pd.read_csv(\"train/train-offers-dataset.csv\")\n",
    "\n",
    "# print the first few rows to make sure that data has been loaded as expected\n",
    "csv_dataset.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Preparar los datos de entreño-test; quitar funciones, normalizar y asignar escaladores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>greenfield</th>\n",
       "      <th>vpc</th>\n",
       "      <th>subnets</th>\n",
       "      <th>connectivity</th>\n",
       "      <th>peerings</th>\n",
       "      <th>directoryservice</th>\n",
       "      <th>otherservices</th>\n",
       "      <th>advsecurity</th>\n",
       "      <th>advlogging</th>\n",
       "      <th>advmonitoring</th>\n",
       "      <th>...</th>\n",
       "      <th>vms</th>\n",
       "      <th>buckets</th>\n",
       "      <th>databases</th>\n",
       "      <th>elb</th>\n",
       "      <th>autoscripts</th>\n",
       "      <th>administered</th>\n",
       "      <th>phase1prediction</th>\n",
       "      <th>phase2prediction</th>\n",
       "      <th>phase3prediction</th>\n",
       "      <th>phase4prediction</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>146120</th>\n",
       "      <td>0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.00</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.8</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2.00</td>\n",
       "      <td>3.25</td>\n",
       "      <td>3.25</td>\n",
       "      <td>1.75</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2063170</th>\n",
       "      <td>0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.00</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.9</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>3.25</td>\n",
       "      <td>5.00</td>\n",
       "      <td>5.00</td>\n",
       "      <td>2.75</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>775165</th>\n",
       "      <td>0</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.25</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.9</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>2.25</td>\n",
       "      <td>3.50</td>\n",
       "      <td>3.50</td>\n",
       "      <td>1.75</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>209612</th>\n",
       "      <td>0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.00</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0.5</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>3.75</td>\n",
       "      <td>5.75</td>\n",
       "      <td>5.75</td>\n",
       "      <td>3.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>580596</th>\n",
       "      <td>0</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.50</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.9</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1.50</td>\n",
       "      <td>2.50</td>\n",
       "      <td>2.50</td>\n",
       "      <td>1.25</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 21 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         greenfield  vpc  subnets  connectivity  peerings  directoryservice  \\\n",
       "146120            0  1.0     1.00             0         1                 0   \n",
       "2063170           0  1.0     1.00             0         1                 1   \n",
       "775165            0  0.5     0.25             0         1                 0   \n",
       "209612            0  1.0     1.00             1         1                 1   \n",
       "580596            0  0.5     0.50             0         1                 0   \n",
       "\n",
       "         otherservices  advsecurity  advlogging  advmonitoring  ...  vms  \\\n",
       "146120             0.0            1           0              0  ...  0.8   \n",
       "2063170            1.0            1           1              0  ...  0.9   \n",
       "775165             0.0            1           1              0  ...  0.9   \n",
       "209612             0.0            1           0              1  ...  0.2   \n",
       "580596             0.0            1           0              0  ...  0.9   \n",
       "\n",
       "         buckets  databases  elb  autoscripts  administered  phase1prediction  \\\n",
       "146120       0.0        1.0    0            0             0              2.00   \n",
       "2063170      0.0        0.0    0            1             0              3.25   \n",
       "775165       0.0        0.0    1            0             1              2.25   \n",
       "209612       0.5        1.0    0            1             1              3.75   \n",
       "580596       1.0        0.0    0            0             1              1.50   \n",
       "\n",
       "         phase2prediction  phase3prediction  phase4prediction  \n",
       "146120               3.25              3.25              1.75  \n",
       "2063170              5.00              5.00              2.75  \n",
       "775165               3.50              3.50              1.75  \n",
       "209612               5.75              5.75              3.00  \n",
       "580596               2.50              2.50              1.25  \n",
       "\n",
       "[5 rows x 21 columns]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# drop features with low occurance/correlation\n",
    "df_train_test_base = pd.DataFrame(csv_dataset)\n",
    "\n",
    "# shuffle the data\n",
    "df_train_test_base_shuffled = shuffle(df_train_test_base, random_state=0)\n",
    "\n",
    "# phaseprediction test train split\n",
    "df_train_test_phase1 = df_train_test_base_shuffled.drop(['phase2prediction', 'phase3prediction', 'phase4prediction'], axis = 1)\n",
    "phase1_x_train = df_train_test_phase1[['greenfield','vpc', 'subnets', 'connectivity', 'peerings', 'directoryservice', 'otherservices', 'advsecurity', 'advlogging', 'advmonitoring', 'advbackup', 'vms', 'buckets', 'databases', 'elb', 'autoscripts', 'administered']]\n",
    "phase1_y_train = df_train_test_phase1['phase1prediction']\n",
    "\n",
    "df_train_test_phase2 = df_train_test_base_shuffled.drop(['phase3prediction', 'phase4prediction'], axis = 1) \n",
    "phase2_x_train = df_train_test_phase2[['greenfield','vpc', 'subnets', 'connectivity', 'peerings', 'directoryservice', 'otherservices', 'advsecurity', 'advlogging', 'advmonitoring', 'advbackup', 'vms', 'buckets', 'databases', 'elb', 'autoscripts', 'administered', 'phase1prediction']]\n",
    "phase2_y_train = df_train_test_phase2['phase2prediction']\n",
    "\n",
    "df_train_test_phase3 = df_train_test_base_shuffled.drop(['phase4prediction'], axis = 1)\n",
    "phase3_x_train = df_train_test_phase3[['greenfield','vpc', 'subnets', 'connectivity', 'peerings', 'directoryservice', 'otherservices', 'advsecurity', 'advlogging', 'advmonitoring', 'advbackup', 'vms', 'buckets', 'databases', 'elb', 'autoscripts', 'administered', 'phase1prediction', 'phase2prediction']]\n",
    "phase3_y_train = df_train_test_phase3['phase3prediction']\n",
    "\n",
    "df_train_test_phase4 = df_train_test_base_shuffled.copy()\n",
    "phase4_x_train = df_train_test_phase4[['greenfield','vpc', 'subnets', 'connectivity', 'peerings', 'directoryservice', 'otherservices', 'advsecurity', 'advlogging', 'advmonitoring', 'advbackup', 'vms', 'buckets', 'databases', 'elb', 'autoscripts', 'administered', 'phase1prediction', 'phase2prediction', 'phase3prediction']]\n",
    "phase4_y_train = df_train_test_phase4['phase4prediction']\n",
    "\n",
    "df_train_test_base_shuffled.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Cargar los datos para validar el modelo de AA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load the csv data sets\n",
    "csv_datavalidation = pd.read_csv(\"validation/validation-offers-dataset.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Preparar los datos de validación; quitar funciones, normalizar y asignar escaladores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>greenfield</th>\n",
       "      <th>vpc</th>\n",
       "      <th>subnets</th>\n",
       "      <th>connectivity</th>\n",
       "      <th>peerings</th>\n",
       "      <th>directoryservice</th>\n",
       "      <th>advsecurity</th>\n",
       "      <th>advlogging</th>\n",
       "      <th>advmonitoring</th>\n",
       "      <th>advbackup</th>\n",
       "      <th>vms</th>\n",
       "      <th>buckets</th>\n",
       "      <th>databases</th>\n",
       "      <th>elb</th>\n",
       "      <th>autoscripts</th>\n",
       "      <th>otherservices</th>\n",
       "      <th>administered</th>\n",
       "      <th>phase1prediction</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>1</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.25</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.3</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>2.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.25</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0.1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.4</td>\n",
       "      <td>0</td>\n",
       "      <td>0.25</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>1</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.50</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.5</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0.4</td>\n",
       "      <td>0</td>\n",
       "      <td>3.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>1</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.75</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.6</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.4</td>\n",
       "      <td>0</td>\n",
       "      <td>1.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>1</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.25</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>1.00</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    greenfield  vpc  subnets  connectivity  peerings  directoryservice  \\\n",
       "18           1  0.5     0.25             1         0                 0   \n",
       "1            1  0.5     0.25             0         0                 0   \n",
       "19           1  0.5     0.50             1         0                 0   \n",
       "8            1  0.5     0.75             0         0                 0   \n",
       "10           1  0.5     0.25             0         0                 0   \n",
       "\n",
       "    advsecurity  advlogging  advmonitoring  advbackup  vms  buckets  \\\n",
       "18            0           0              0          0  0.3      0.5   \n",
       "1             0           0              1          0  0.1      0.0   \n",
       "19            0           0              0          0  0.0      0.0   \n",
       "8             0           0              0          0  0.6      1.0   \n",
       "10            0           0              0          0  0.1      0.0   \n",
       "\n",
       "    databases  elb  autoscripts  otherservices  administered  phase1prediction  \n",
       "18        0.0    0            0            0.0             0              2.00  \n",
       "1         0.0    0            0            0.4             0              0.25  \n",
       "19        0.5    1            0            0.4             0              3.00  \n",
       "8         0.0    0            0            0.4             0              1.00  \n",
       "10        0.0    0            0            0.0             0              1.00  "
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# drop features with low occurance/correlation\n",
    "df_validation_base = pd.DataFrame(csv_datavalidation)\n",
    "          \n",
    "# shuffle the data\n",
    "df_validation_base_shuffled = shuffle(df_validation_base, random_state=0)\n",
    "\n",
    "# phaseprediction test train split\n",
    "df_validation_phase1 = df_validation_base_shuffled.drop(['phase2prediction', 'phase3prediction', 'phase4prediction'], axis = 1)\n",
    "phase1_x_validation = df_validation_phase1[['greenfield','vpc', 'subnets', 'connectivity', 'peerings', 'directoryservice', 'otherservices', 'advsecurity', 'advlogging', 'advmonitoring', 'advbackup', 'vms', 'buckets', 'databases', 'elb', 'autoscripts', 'administered']]\n",
    "phase1_y_validation = df_validation_phase1['phase1prediction']\n",
    "\n",
    "df_validation_phase2 = df_validation_base_shuffled.drop(['phase3prediction', 'phase4prediction'], axis = 1) \n",
    "phase2_x_validation = df_validation_phase2[['greenfield','vpc', 'subnets', 'connectivity', 'peerings', 'directoryservice', 'otherservices', 'advsecurity', 'advlogging', 'advmonitoring', 'advbackup', 'vms', 'buckets', 'databases', 'elb', 'autoscripts', 'administered', 'phase1prediction']]\n",
    "phase2_y_validation = df_validation_phase2['phase2prediction']\n",
    "\n",
    "df_validation_phase3 = df_validation_base_shuffled.drop(['phase4prediction'], axis = 1)\n",
    "phase3_x_validation = df_validation_phase3[['greenfield','vpc', 'subnets', 'connectivity', 'peerings', 'directoryservice', 'otherservices', 'advsecurity', 'advlogging', 'advmonitoring', 'advbackup', 'vms', 'buckets', 'databases', 'elb', 'autoscripts', 'administered', 'phase1prediction', 'phase2prediction']]\n",
    "phase3_y_validation = df_validation_phase3['phase3prediction']\n",
    "\n",
    "df_validation_phase4 = df_validation_base_shuffled.copy()\n",
    "phase4_x_validation = df_validation_phase4[['greenfield','vpc', 'subnets', 'connectivity', 'peerings', 'directoryservice', 'otherservices', 'advsecurity', 'advlogging', 'advmonitoring', 'advbackup', 'vms', 'buckets', 'databases', 'elb', 'autoscripts', 'administered', 'phase1prediction', 'phase2prediction', 'phase3prediction']]\n",
    "phase4_y_validation = df_validation_phase4['phase4prediction']\n",
    "\n",
    "df_validation_phase1.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Evaluacion del modelo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\n# uuid for the evaluation run\\neval_id = uuid.uuid4()\\n\\n# datetime of the evaluation run\\nnow = datetime.datetime.now().strftime(\"%Y-%m-%d %H:%M:%S\")\\n\\n# results list\\nresults_list = []\\n\\ndef k_fold_score_model(phase_number, phase_name, X_train, Y_train):\\n    print(f\"Evaluating model for phase: {phase_number}: {phase_name}\")\\n    seed = 7\\n    kfold = model_selection.KFold(n_splits=10, random_state=seed, shuffle=True)\\n\\n    model = xgb.XGBRegressor(\\n        booster=\"gbtree\", \\n        n_jobs=6, \\n        verbosity=0, \\n        n_estimators=EPOCHS, \\n        importance_type=\"weight\", \\n        random_state=42, \\n        eval_metric=\"mae\"\\n    )\\n    \\n    print(f\"Scoring neg_mean_absolute_error for phase: {phase_number}: {phase_name}\")\\n    scoring_mae = \\'neg_mean_absolute_error\\'\\n    result_mae = model_selection.cross_val_score(model, X_train, Y_train, cv=kfold, scoring=scoring_mae)\\n    \\n    print(f\"Scoring neg_mean_squared_error for phase: {phase_number}: {phase_name}\")\\n    scoring_mse = \\'neg_mean_squared_error\\'\\n    result_mse = model_selection.cross_val_score(model, X_train, Y_train, cv=kfold, scoring=scoring_mse)\\n\\n    print(f\"Scoring r2 (r squared) for phase: {phase_number}: {phase_name}\")\\n    scoring_r2 = \\'r2\\'\\n    result_r2 = model_selection.cross_val_score(model, X_train, Y_train, cv=kfold, scoring=scoring_r2)\\n    \\n    score_results = [eval_id,now,phase_number,phase_name,result_mse.mean(),result_mse.std(),result_mae.mean(),result_mae.std(),result_r2.mean(),result_r2.std()]\\n    results_list.append(score_results)\\n\\n\\n# execute ML\\nk_fold_score_model(\"1\", \"Recopilacion\", phase1_x_train, phase1_y_train)\\nk_fold_score_model(\"2\", \"Diseno\", phase2_x_train, phase2_y_train)\\nk_fold_score_model(\"3\", \"Implantacion\", phase3_x_train, phase3_y_train)\\nk_fold_score_model(\"4\", \"Soporte\", phase4_x_train, phase4_y_train)\\n\\n# write the text and csv results\\ndf_score_results = pd.DataFrame(results_list, columns = [\\'evaluation_id\\',\\'datetime\\',\\'phasenumber\\',\\'phasename\\',\\'mse_mean\\',\\'mse_std\\',\\'mae_mean\\',\\'mae_std\\',\\'r2_mean\\',\\'r2_std\\'])\\n\\nwith open(\"analysis/model/xgboost/model-evaluation.csv\", \"a+\") as csv_file:\\n    df_score_results.to_csv(csv_file, header=False, index=False)\\n    \\ndf_score_results.head()\\n'"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# uuid for the evaluation run\n",
    "eval_id = uuid.uuid4()\n",
    "\n",
    "# datetime of the evaluation run\n",
    "now = datetime.datetime.now().strftime(\"%Y-%m-%d %H:%M:%S\")\n",
    "\n",
    "# results list\n",
    "results_list = []\n",
    "\n",
    "def k_fold_score_model(phase_number, phase_name, X_train, Y_train):\n",
    "    print(f\"Evaluating model for phase: {phase_number}: {phase_name}\")\n",
    "    seed = 7\n",
    "    kfold = model_selection.KFold(n_splits=10, random_state=seed, shuffle=True)\n",
    "\n",
    "    model = xgb.XGBRegressor(\n",
    "        booster=\"gbtree\", \n",
    "        n_jobs=6, \n",
    "        verbosity=0, \n",
    "        n_estimators=EPOCHS, \n",
    "        importance_type=\"weight\", \n",
    "        random_state=42, \n",
    "        eval_metric=\"mae\"\n",
    "    )\n",
    "    \n",
    "    print(f\"Scoring neg_mean_absolute_error for phase: {phase_number}: {phase_name}\")\n",
    "    scoring_mae = 'neg_mean_absolute_error'\n",
    "    result_mae = model_selection.cross_val_score(model, X_train, Y_train, cv=kfold, scoring=scoring_mae)\n",
    "    \n",
    "    print(f\"Scoring neg_mean_squared_error for phase: {phase_number}: {phase_name}\")\n",
    "    scoring_mse = 'neg_mean_squared_error'\n",
    "    result_mse = model_selection.cross_val_score(model, X_train, Y_train, cv=kfold, scoring=scoring_mse)\n",
    "\n",
    "    print(f\"Scoring r2 (r squared) for phase: {phase_number}: {phase_name}\")\n",
    "    scoring_r2 = 'r2'\n",
    "    result_r2 = model_selection.cross_val_score(model, X_train, Y_train, cv=kfold, scoring=scoring_r2)\n",
    "    \n",
    "    score_results = [eval_id,now,phase_number,phase_name,result_mse.mean(),result_mse.std(),result_mae.mean(),result_mae.std(),result_r2.mean(),result_r2.std()]\n",
    "    results_list.append(score_results)\n",
    "\n",
    "\n",
    "# execute ML\n",
    "k_fold_score_model(\"1\", \"Recopilacion\", phase1_x_train, phase1_y_train)\n",
    "k_fold_score_model(\"2\", \"Diseno\", phase2_x_train, phase2_y_train)\n",
    "k_fold_score_model(\"3\", \"Implantacion\", phase3_x_train, phase3_y_train)\n",
    "k_fold_score_model(\"4\", \"Soporte\", phase4_x_train, phase4_y_train)\n",
    "\n",
    "# write the text and csv results\n",
    "df_score_results = pd.DataFrame(results_list, columns = ['evaluation_id','datetime','phasenumber','phasename','mse_mean','mse_std','mae_mean','mae_std','r2_mean','r2_std'])\n",
    "\n",
    "with open(\"analysis/model/xgboost/model-evaluation.csv\", \"a+\") as csv_file:\n",
    "    df_score_results.to_csv(csv_file, header=False, index=False)\n",
    "    \n",
    "df_score_results.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Buscar los hyperparametros optimales"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Searching optimal hyperparameters for phase: 1: Recopilacion\n",
      "Fitting the data for phase: 1: Recopilacion\n",
      "Fitting 2 folds for each of 20 candidates, totalling 40 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=4)]: Using backend LokyBackend with 4 concurrent workers.\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-8-2146f00316b7>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     22\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     23\u001b[0m \u001b[0;31m# execute ML\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 24\u001b[0;31m \u001b[0msearch_optimal_hyperparameters\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"1\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"Recopilacion\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mphase1_x_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mphase1_y_train\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     25\u001b[0m \u001b[0msearch_optimal_hyperparameters\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"2\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"Diseno\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mphase2_x_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mphase2_y_train\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     26\u001b[0m \u001b[0msearch_optimal_hyperparameters\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"3\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"Implantacion\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mphase3_x_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mphase3_y_train\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-8-2146f00316b7>\u001b[0m in \u001b[0;36msearch_optimal_hyperparameters\u001b[0;34m(phase_number, phase_name, x_train, y_train)\u001b[0m\n\u001b[1;32m     15\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     16\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf\"Fitting the data for phase: {phase_number}: {phase_name}\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 17\u001b[0;31m     \u001b[0msearch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     18\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     19\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf\"Reporting best scores for phase: {phase_number}: {phase_name}\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.7/site-packages/sklearn/model_selection/_search.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, X, y, groups, **fit_params)\u001b[0m\n\u001b[1;32m    708\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0mresults\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    709\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 710\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_run_search\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mevaluate_candidates\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    711\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    712\u001b[0m         \u001b[0;31m# For multi-metric evaluation, store the best_index_, best_params_ and\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.7/site-packages/sklearn/model_selection/_search.py\u001b[0m in \u001b[0;36m_run_search\u001b[0;34m(self, evaluate_candidates)\u001b[0m\n\u001b[1;32m   1482\u001b[0m         evaluate_candidates(ParameterSampler(\n\u001b[1;32m   1483\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mparam_distributions\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mn_iter\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1484\u001b[0;31m             random_state=self.random_state))\n\u001b[0m",
      "\u001b[0;32m/opt/conda/lib/python3.7/site-packages/sklearn/model_selection/_search.py\u001b[0m in \u001b[0;36mevaluate_candidates\u001b[0;34m(candidate_params)\u001b[0m\n\u001b[1;32m    687\u001b[0m                                \u001b[0;32mfor\u001b[0m \u001b[0mparameters\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mtrain\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtest\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    688\u001b[0m                                in product(candidate_params,\n\u001b[0;32m--> 689\u001b[0;31m                                           cv.split(X, y, groups)))\n\u001b[0m\u001b[1;32m    690\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    691\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mout\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m<\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.7/site-packages/joblib/parallel.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, iterable)\u001b[0m\n\u001b[1;32m   1015\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1016\u001b[0m             \u001b[0;32mwith\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_backend\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mretrieval_context\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1017\u001b[0;31m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mretrieve\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1018\u001b[0m             \u001b[0;31m# Make sure that we get a last message telling us we are done\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1019\u001b[0m             \u001b[0melapsed_time\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtime\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtime\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_start_time\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.7/site-packages/joblib/parallel.py\u001b[0m in \u001b[0;36mretrieve\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    907\u001b[0m             \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    908\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0mgetattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_backend\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'supports_timeout'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 909\u001b[0;31m                     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_output\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mextend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mjob\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    910\u001b[0m                 \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    911\u001b[0m                     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_output\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mextend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mjob\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.7/site-packages/joblib/_parallel_backends.py\u001b[0m in \u001b[0;36mwrap_future_result\u001b[0;34m(future, timeout)\u001b[0m\n\u001b[1;32m    560\u001b[0m         AsyncResults.get from multiprocessing.\"\"\"\n\u001b[1;32m    561\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 562\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mfuture\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mresult\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    563\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mLokyTimeoutError\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    564\u001b[0m             \u001b[0;32mraise\u001b[0m \u001b[0mTimeoutError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.7/concurrent/futures/_base.py\u001b[0m in \u001b[0;36mresult\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    428\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__get_result\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    429\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 430\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_condition\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwait\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    431\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    432\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_state\u001b[0m \u001b[0;32min\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mCANCELLED\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mCANCELLED_AND_NOTIFIED\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.7/threading.py\u001b[0m in \u001b[0;36mwait\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    294\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m    \u001b[0;31m# restore state no matter what (e.g., KeyboardInterrupt)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    295\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mtimeout\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 296\u001b[0;31m                 \u001b[0mwaiter\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0macquire\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    297\u001b[0m                 \u001b[0mgotit\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    298\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "def search_optimal_hyperparameters(phase_number, phase_name, x_train, y_train):\n",
    "    print(f\"Searching optimal hyperparameters for phase: {phase_number}: {phase_name}\")\n",
    "    \n",
    "    xgb_model = xgb.XGBRegressor()\n",
    "\n",
    "    params = {\n",
    "        \"colsample_bytree\": uniform(0.7, 0.3),\n",
    "        \"gamma\": uniform(0, 0.5),\n",
    "        \"learning_rate\": uniform(0.03, 0.3), # default 0.1 \n",
    "        \"max_depth\": randint(2, 6), # default 3\n",
    "        \"subsample\": uniform(0.6, 0.4)\n",
    "    }\n",
    "\n",
    "    search = RandomizedSearchCV(xgb_model, param_distributions=params, random_state=42, n_iter=200, cv=5, verbose=3, n_jobs=4, return_train_score=True)\n",
    "\n",
    "    print(f\"Fitting the data for phase: {phase_number}: {phase_name}\")\n",
    "    search.fit(x_train, y_train)\n",
    "\n",
    "    print(f\"Reporting best scores for phase: {phase_number}: {phase_name}\")\n",
    "    report_best_scores(search.cv_results_, 1)\n",
    "\n",
    "  \n",
    "# execute ML\n",
    "search_optimal_hyperparameters(\"1\", \"Recopilacion\", phase1_x_train, phase1_y_train)\n",
    "search_optimal_hyperparameters(\"2\", \"Diseno\", phase2_x_train, phase2_y_train)\n",
    "search_optimal_hyperparameters(\"3\", \"Implantacion\", phase3_x_train, phase3_y_train)\n",
    "search_optimal_hyperparameters(\"4\", \"Soporte\", phase4_x_train, phase4_y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Determinar el mejor model utilizando early stopping"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "best_model_iterations = {}\n",
    "\n",
    "\n",
    "def determine_early_stopping(phase_number, phase_name, x_train, y_train):\n",
    "    print(f\"Determine best early stopping run for phase: {phase_number}: {phase_name}\")\n",
    "    \n",
    "    xgb_model = xgb.XGBRegressor(\n",
    "        booster=\"gbtree\", \n",
    "        n_jobs=4, \n",
    "        verbosity=0, \n",
    "        n_estimators=EPOCHS, \n",
    "        importance_type=\"weight\", \n",
    "        random_state=42, \n",
    "        eval_metric=\"mae\"\n",
    "    )\n",
    "\n",
    "    X_axis_train, X_axis_test, y_axis_train, y_axis_test = train_test_split(x_train, y_train, random_state=42)\n",
    "\n",
    "    xgb_model.fit(X_axis_train, y_axis_train, early_stopping_rounds=PATIENCE_THRESHOLD, eval_set=[(X_axis_test, y_axis_test)])\n",
    "\n",
    "    y_pred = xgb_model.predict(X_axis_test)\n",
    "\n",
    "    print(\"best score: {0}, best iteration: {1}, best ntree limit {2}\".format(xgb_model.best_score, xgb_model.best_iteration, xgb_model.best_ntree_limit))\n",
    "    best_model_iterations[phase_number] = xgb_model.best_iteration + 1\n",
    "    print(\"**************************************\")\n",
    "\n",
    "  \n",
    "# execute ML\n",
    "determine_early_stopping(\"1\", \"Recopilacion\", phase1_x_train, phase1_y_train)\n",
    "determine_early_stopping(\"2\", \"Diseno\", phase2_x_train, phase2_y_train)\n",
    "determine_early_stopping(\"3\", \"Implantacion\", phase3_x_train, phase3_y_train)\n",
    "determine_early_stopping(\"4\", \"Soporte\", phase4_x_train, phase4_y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Generar el modelo y guardarlo al disco"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def save_best_model(phase_number, phase_name, phase_params, phase_predictor, x_train, y_train):\n",
    "    print(f\"Save best model for phase: {phase_number}: {phase_name}\")\n",
    "    print(f\"Column number: {x_train.num_col()}\")\n",
    "    print(f\"Best number of rounds: {best_model_iterations[phase_number]} for phase: {phase_number}: {phase_name}\")\n",
    "    best_model = xgb.train(\n",
    "        phase_params, \n",
    "        x_train, \n",
    "        num_boost_round=best_model_iterations[phase_number], \n",
    "        evals=[(y_train, phase_predictor)]\n",
    "    )\n",
    "    \n",
    "    xgb.plot_importance(best_model)\n",
    "\n",
    "    # converts the target tree to a graphviz instance\n",
    "    xgb.to_graphviz(best_model, num_trees=best_model.best_iteration)\n",
    "    \n",
    "    print(f\"Saving model to phase_{phase_number}_model.model\")\n",
    "    best_model.save_model(f\"models-saved/xgboost/phase_{phase_number}_model.model\")\n",
    "    \n",
    "\n",
    "# model 1\n",
    "phase1_params = {\n",
    "    \"booster\": \"gbtree\",\n",
    "    \"importance_type\": \"weight\",\n",
    "    \"n_jobs\": 6,\n",
    "    \"random_state\": 42, \n",
    "    \"eval_metric\": \"mae\",\n",
    "    \"colsample_bytree\": 0.7992694074557947,\n",
    "    \"gamma\": 0.03177917514301182,\n",
    "    \"learning_rate\": 0.12329469651469865,\n",
    "    \"max_depth\": 5,\n",
    "    \"subsample\": 0.8918424713352255\n",
    "}\n",
    "\n",
    "# model 2\n",
    "phase2_params = {\n",
    "    \"booster\": \"gbtree\",\n",
    "    \"importance_type\": \"weight\",\n",
    "    \"n_jobs\": 6, \n",
    "    \"random_state\": 42, \n",
    "    \"eval_metric\": \"mae\",\n",
    "    \"colsample_bytree\": 0.796805916483275,\n",
    "    \"gamma\": 0.02170039164908638,\n",
    "    \"learning_rate\": 0.30739299906707884,\n",
    "    \"max_depth\": 5,\n",
    "    \"subsample\": 0.7011960671956965\n",
    "}\n",
    "\n",
    "# model 3\n",
    "phase3_params = {\n",
    "    \"booster\": \"gbtree\",\n",
    "    \"importance_type\": \"weight\",\n",
    "    \"n_jobs\": 6,\n",
    "    \"random_state\": 42, \n",
    "    \"eval_metric\": \"mae\",\n",
    "    \"colsample_bytree\": 0.796805916483275,\n",
    "    \"gamma\": 0.02170039164908638,\n",
    "    \"learning_rate\": 0.30739299906707884,\n",
    "    \"max_depth\": 5,\n",
    "    \"subsample\": 0.7011960671956965\n",
    "}\n",
    "\n",
    "# model 4\n",
    "phase4_params = {\n",
    "    \"booster\": \"gbtree\",\n",
    "    \"importance_type\": \"weight\",\n",
    "    \"n_jobs\": 6,\n",
    "    \"random_state\": 42, \n",
    "    \"eval_metric\": \"mae\",\n",
    "    \"colsample_bytree\": 0.9248848696025762,\n",
    "    \"gamma\": 0.01523607636679708,\n",
    "    \"learning_rate\": 0.290164494322417,\n",
    "    \"max_depth\": 3,\n",
    "    \"subsample\": 0.758865533001633\n",
    "}\n",
    "\n",
    "# execute ML\n",
    "X_dmatrix_train_phase1, X_dmatrix_test_phase1, y_dmatrix_train_phase1, y_dmatrix_test_phase1 = train_test_split(phase1_x_train,phase1_y_train,test_size=.3, random_state=42)\n",
    "dtrain_phase1 = xgb.DMatrix(X_dmatrix_train_phase1, label=y_dmatrix_train_phase1)\n",
    "dtest_phase1 = xgb.DMatrix(X_dmatrix_test_phase1, label=y_dmatrix_test_phase1)\n",
    "save_best_model(\"1\", \"Recopilacion\", phase1_params, \"phase1prediction\", dtrain_phase1, dtest_phase1)\n",
    "\n",
    "X_dmatrix_train_phase2, X_dmatrix_test_phase2, y_dmatrix_train_phase2, y_dmatrix_test_phase2 = train_test_split(phase2_x_train,phase2_y_train,test_size=.3, random_state=42)\n",
    "dtrain_phase2 = xgb.DMatrix(X_dmatrix_train_phase2, label=y_dmatrix_train_phase2)\n",
    "dtest_phase2 = xgb.DMatrix(X_dmatrix_test_phase2, label=y_dmatrix_test_phase2)\n",
    "save_best_model(\"2\", \"Diseno\", phase2_params, \"phase2prediction\", dtrain_phase2, dtest_phase2)\n",
    "\n",
    "X_dmatrix_train_phase3, X_dmatrix_test_phase3, y_dmatrix_train_phase3, y_dmatrix_test_phase3 = train_test_split(phase3_x_train,phase3_y_train,test_size=.3, random_state=42)\n",
    "dtrain_phase3 = xgb.DMatrix(X_dmatrix_train_phase3, label=y_dmatrix_train_phase3)\n",
    "dtest_phase3 = xgb.DMatrix(X_dmatrix_test_phase3, label=y_dmatrix_test_phase3)\n",
    "save_best_model(\"3\", \"Implantacion\", phase3_params, \"phase3prediction\", dtrain_phase3, dtest_phase3)\n",
    "\n",
    "X_dmatrix_train_phase4, X_dmatrix_test_phase4, y_dmatrix_train_phase4, y_dmatrix_test_phase4 = train_test_split(phase4_x_train,phase4_y_train,test_size=.3, random_state=42)\n",
    "dtrain_phase4 = xgb.DMatrix(X_dmatrix_train_phase4, label=y_dmatrix_train_phase4)\n",
    "dtest_phase4 = xgb.DMatrix(X_dmatrix_test_phase4, label=y_dmatrix_test_phase4)\n",
    "save_best_model(\"4\", \"Soporte\", phase4_params, \"phase4prediction\", dtrain_phase4, dtest_phase4)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Predecir las jornadas por fase con los datos de validación"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# uuid for the evaluation run\n",
    "eval_id = uuid.uuid4()\n",
    "\n",
    "# datetime of the evaluation run\n",
    "now = datetime.datetime.now().strftime(\"%Y-%m-%d %H:%M:%S\")\n",
    "\n",
    "# results list\n",
    "results_list = []\n",
    "\n",
    "\n",
    "def predict_phases(phase_number, phase_name, phase_predictions, X_validation):\n",
    "    print(f\"Phase predictions for phase: {phase_number}: {phase_name}\")\n",
    "    RESULT_TYPE_OVER_ESTIMATE = \"SOBRE_ESTIMACION\"\n",
    "    RESULT_TYPE_UNDER_ESTIMATE = \"SUB_ESTIMACION\"\n",
    "    RESULT_TYPE_EQUAL_ESTIMATE = \"EQUAL_ESTIMACION\"\n",
    "    \n",
    "    loaded_model = xgb.Booster()\n",
    "    loaded_model.load_model(f\"models-saved/xgboost/phase_{phase_number}_model.model\")\n",
    "    \n",
    "    # get predictions based on validation data set\n",
    "    predictors = loaded_model.predict(X_validation)\n",
    "    \n",
    "    # enumerate the predictions\n",
    "    for idx, j in enumerate(predictors):\n",
    "        predicted = get_min_value(j, phase_number)\n",
    "        actual = phase_predictions[idx]\n",
    "        loss = 0\n",
    "        percentage = 0\n",
    "        result_type = RESULT_TYPE_EQUAL_ESTIMATE\n",
    "        \n",
    "        # OVERestimate\n",
    "        if predicted > actual:\n",
    "            loss = predicted - actual\n",
    "            if loss > 0 and actual > 0:\n",
    "                percentage = (loss/predicted)*100\n",
    "            result_type = RESULT_TYPE_OVER_ESTIMATE\n",
    "        # UNDERestimate\n",
    "        elif actual > predicted:\n",
    "            loss = actual - predicted\n",
    "            if loss > 0 and actual > 0:\n",
    "                percentage = ((loss/actual)*100) * -1\n",
    "            \n",
    "            result_type = RESULT_TYPE_UNDER_ESTIMATE\n",
    "\n",
    "        predict_result = [eval_id, idx, now,phase_number, phase_name, actual, predicted, loss, percentage, result_type]\n",
    "        results_list.append(predict_result)\n",
    "            \n",
    "\n",
    "# execute predictions using the validation dataset\n",
    "dvalidation_phase1 = xgb.DMatrix(phase1_x_validation, label=phase1_y_validation)\n",
    "predict_phases(1, \"Recopilacion\", phase1_y_validation, dvalidation_phase1)\n",
    "\n",
    "dvalidation_phase2 = xgb.DMatrix(phase2_x_validation, label=phase2_y_validation)\n",
    "predict_phases(2, \"Diseno\", phase2_y_validation, dvalidation_phase2)\n",
    "\n",
    "dvalidation_phase3 = xgb.DMatrix(phase3_x_validation, label=phase3_y_validation)\n",
    "predict_phases(3, \"Implantacion\", phase3_y_validation, dvalidation_phase3)\n",
    "\n",
    "dvalidation_phase4 = xgb.DMatrix(phase4_x_validation, label=phase4_y_validation)\n",
    "predict_phases(4, \"Soporte\", phase4_y_validation, dvalidation_phase4)\n",
    "\n",
    "# write the text and csv result\n",
    "df_prediction_results = pd.DataFrame(results_list, columns = ['evaluation_id','correlation_id','datetime','phasenumber','phasename','actual','predicted','loss','percentage', 'result_type']).sort_values('correlation_id', ascending=True)\n",
    "\n",
    "model_predictions_csv = f\"analysis/predictions/xgboost/model-predictions_{eval_id}.csv\"\n",
    "with open(model_predictions_csv, \"w+\") as csv_file:\n",
    "    df_prediction_results.to_csv(csv_file, header=True, index=False)\n",
    "print(\"\\n\")\n",
    "print(f\"Evaluatiuon id: {eval_id}\")\n",
    "print(\"\\n\")\n",
    "\n",
    "df_prediction_results.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Analisis de los resultados"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "conn = sqlite3.connect(\":memory:\")\n",
    "df_model_predictions = pd.read_csv(model_predictions_csv)\n",
    "df_model_predictions.to_sql(\"predictions\", conn, if_exists='append', index=False)\n",
    "\n",
    "query_details = [ {\"phasenumber\": 1, \"phasename\": \"Recopilacion\", \"min_val\": -0.5, \"max_val\": 0.5}, \n",
    "                  {\"phasenumber\": 2, \"phasename\": \"Diseno\", \"min_val\": -0.75, \"max_val\": 0.75},\n",
    "                  {\"phasenumber\": 3, \"phasename\": \"Implantacion\", \"min_val\": -0.75, \"max_val\": 0.75},\n",
    "                  {\"phasenumber\": 4, \"phasename\": \"Soporte\", \"min_val\": -0.50, \"max_val\": 0.50}\n",
    "                ]\n",
    "\n",
    "accum_acceptable_offers = 0\n",
    "accum_precise_offers = 0\n",
    "accum_non_acceptable_offers = 0\n",
    "accum_non_acceptable_under = 0\n",
    "accum_non_acceptable_over = 0\n",
    "accum_total_offers = 0\n",
    "\n",
    "# uuid for the evaluation run\n",
    "eval_id = uuid.uuid4()\n",
    "\n",
    "# datetime of the evaluation run\n",
    "now = datetime.datetime.now().strftime(\"%Y-%m-%d %H:%M:%S\")\n",
    "\n",
    "phase_analysis_results = []\n",
    "    \n",
    "for detail in query_details:\n",
    "    print(\"####################################################################################\")\n",
    "    print(\"Estadisticas de fase {}: {}\".format(detail['phasenumber'], detail['phasename']))\n",
    "    print(\"\\n\")\n",
    "    \n",
    "    phase_query_ofertas_precise = \"SELECT COUNT(correlation_id) AS ofertas_precise FROM predictions WHERE phasenumber = {} AND ((actual_std-predicted_std) = 0)\".format(detail['phasenumber'])\n",
    "    pd.set_option('display.max_rows', df_model_predictions.shape[0]+1)\n",
    "    df_precise_offers = pd.read_sql_query(phase_query_ofertas_precise, conn)\n",
    "    \n",
    "    phase_query_ofertas_aceptable = \"SELECT COUNT(correlation_id) AS ofertas_aceptable FROM predictions WHERE phasenumber = {} AND ((actual_std-predicted_std) >= {} AND (actual_std-predicted_std) <= {})\".format(detail['phasenumber'], detail['min_val'], detail['max_val'])\n",
    "    pd.set_option('display.max_rows', df_model_predictions.shape[0]+1)\n",
    "    df_acceptable_offers = pd.read_sql_query(phase_query_ofertas_aceptable, conn)\n",
    "\n",
    "    phase_query_ofertas_noaceptable = \"SELECT COUNT(correlation_id) AS ofertas_no_aceptable FROM predictions WHERE phasenumber = {} AND ((actual_std-predicted_std) < {} OR (actual_std-predicted_std) > {})\".format(detail['phasenumber'], detail['min_val'], detail['max_val'])\n",
    "    pd.set_option('display.max_rows', df_model_predictions.shape[0]+1)\n",
    "    df_non_acceptable_offers = pd.read_sql_query(phase_query_ofertas_noaceptable, conn)\n",
    "    \n",
    "    phase_query_ofertas_under = \"SELECT COUNT(correlation_id) AS sub_estimaciones FROM predictions WHERE phasenumber = {} AND ((actual_std-predicted_std) > {})\".format(detail['phasenumber'], detail['max_val'])\n",
    "    pd.set_option('display.max_rows', df_model_predictions.shape[0]+1)\n",
    "    df_non_acceptable_under = pd.read_sql_query(phase_query_ofertas_under, conn)\n",
    "    \n",
    "    phase_query_ofertas_over = \"SELECT COUNT(correlation_id) AS sobre_estimaciones FROM predictions WHERE phasenumber = {} AND ((actual_std-predicted_std) < {})\".format(detail['phasenumber'], detail['min_val'])\n",
    "    pd.set_option('display.max_rows', df_model_predictions.shape[0]+1)\n",
    "    df_non_acceptable_over = pd.read_sql_query(phase_query_ofertas_over, conn)\n",
    "    \n",
    "    precise_offers = df_precise_offers['ofertas_precise'].iloc[0]\n",
    "    acceptable_offers = (df_acceptable_offers['ofertas_aceptable'].iloc[0]) - precise_offers\n",
    "    non_acceptable_offers = df_non_acceptable_offers['ofertas_no_aceptable'].iloc[0]\n",
    "    total_offers = precise_offers + acceptable_offers + non_acceptable_offers\n",
    "    acceptable_percentage = \"{:.2f}\".format(((precise_offers + acceptable_offers)/total_offers)*100)\n",
    "    margin_error = detail['max_val'] * 8\n",
    "\n",
    "    under_estimations = df_non_acceptable_under['sub_estimaciones'].iloc[0]\n",
    "    over_estimations = df_non_acceptable_over['sobre_estimaciones'].iloc[0]\n",
    "    \n",
    "    accum_acceptable_offers = accum_acceptable_offers + acceptable_offers\n",
    "    accum_non_acceptable_offers = accum_non_acceptable_offers + non_acceptable_offers\n",
    "    accum_precise_offers = accum_precise_offers + precise_offers\n",
    "    accum_non_acceptable_under = accum_non_acceptable_under + under_estimations\n",
    "    accum_non_acceptable_over = accum_non_acceptable_over + over_estimations\n",
    "    accum_total_offers = accum_total_offers + total_offers\n",
    "    \n",
    "    table = PrettyTable(['ofertas total','ofertas precisas','ofertas aceptable','ofertas no aceptable','aceptable %','margen error horas +/-','sub estimaciones','sobre estimaciones'])\n",
    "    table.add_row([\n",
    "        total_offers,\n",
    "        precise_offers,\n",
    "        acceptable_offers, \n",
    "        non_acceptable_offers,\n",
    "        acceptable_percentage+\"%\",\n",
    "        margin_error,\n",
    "        under_estimations,\n",
    "        over_estimations\n",
    "    ])\n",
    "\n",
    "    print(table)\n",
    "    print(\"\\n\")\n",
    "    \n",
    "    phase_query_ofertas = \"SELECT correlation_id AS oferta, phasenumber, phasename, actual_std AS actual, predicted_std As predicted, actual_std-predicted_std As diff, printf('%.2f', CASE WHEN predicted_std > actual_std THEN ((predicted_std-actual_std)/predicted_std)*100 WHEN actual_std > predicted_std THEN ((actual_std-predicted_std)/actual_std)*100*-1 ELSE 0 END) AS 'diff %' FROM predictions WHERE phasenumber = {} ORDER BY DIFF ASC\".format(detail['phasenumber'])\n",
    "    print(\"POR OFERTA: fase {} - {}\".format(detail['phasenumber'], detail['phasename']))\n",
    "    pd.set_option('display.max_rows', df_model_predictions.shape[0]+1)\n",
    "    df_prediction_by_offer = pd.read_sql_query(phase_query_ofertas, conn)\n",
    "    print(pd.DataFrame(df_prediction_by_offer))\n",
    "    print(\"\\n\")\n",
    "    \n",
    "    validation_offer_results_csv = \"analysis/predictions/linearlearner/validation-metrics-offers-{}.csv\".format(eval_id)\n",
    "    with open(validation_offer_results_csv, \"a+\") as csv_file:\n",
    "        pd.DataFrame(df_prediction_by_offer).to_csv(csv_file, header=False, index=False)\n",
    "    \n",
    "    phase_data = [eval_id, now, detail['phasenumber'], detail['phasename'], total_offers, precise_offers, acceptable_offers, non_acceptable_offers, acceptable_percentage, margin_error, under_estimations, over_estimations]\n",
    "    phase_analysis_results.append(phase_data)\n",
    "  \n",
    "\n",
    "print(\"####################################################################################\")\n",
    "print(\"Totales de todas las fases\")\n",
    "accum_table = PrettyTable(['fases total','fases precisa','fases aceptable','fases no aceptable','aceptable %','sub estimaciones','sobre estimaciones'])\n",
    "\n",
    "accum_acceptable_percentage = \"{:.2f}\".format(((accum_precise_offers + accum_acceptable_offers)/accum_total_offers)*100)\n",
    "accum_table.add_row([\n",
    "    accum_total_offers, \n",
    "    accum_precise_offers,\n",
    "    accum_acceptable_offers, \n",
    "    accum_non_acceptable_offers,\n",
    "    accum_acceptable_percentage,\n",
    "    accum_non_acceptable_under,\n",
    "    accum_non_acceptable_over\n",
    "])\n",
    "\n",
    "print(accum_table)\n",
    "print(\"\\n\")\n",
    "    \n",
    "phase_query_ofertas = \"SELECT correlation_id AS oferta, phasenumber, phasename, actual_std AS actual, predicted_std As predicted, actual_std-predicted_std As diff, printf('%.2f', CASE WHEN predicted_std > actual_std THEN ((predicted_std-actual_std)/predicted_std)*100 WHEN actual_std > predicted_std THEN ((actual_std-predicted_std)/actual_std)*100*-1 ELSE 0 END) AS 'diff %' FROM predictions ORDER BY correlation_id, phasenumber ASC\"\n",
    "print(\"####################################################################################\")\n",
    "print(\"CADA FASE AGRUPADO POR OFERTA\")\n",
    "print(\"\\n\")\n",
    "pd.set_option('display.max_rows', df_model_predictions.shape[0]+1)\n",
    "print(pd.read_sql_query(phase_query_ofertas, conn))\n",
    "print(\"\\n\")\n",
    "\n",
    "total_data = [eval_id, now, 5, 'Total', accum_total_offers, accum_precise_offers, accum_acceptable_offers, accum_non_acceptable_offers, accum_acceptable_percentage, 0, accum_non_acceptable_under, accum_non_acceptable_over]\n",
    "phase_analysis_results.append(total_data)\n",
    "df_analysis_results = pd.DataFrame(phase_analysis_results, columns = ['evaluation_id', 'datetime', 'phasenumber', 'phasename', 'ofertas_total','estimaciones_precisa','ofertas_aceptable','ofertas_no_aceptable','percentage_aceptable','margen error horas +/-','sub_estimaciones','sobre_estimaciones'])\n",
    "\n",
    "validation_results_csv = \"analysis/predictions/linearlearner/validation-metrics.csv\"\n",
    "with open(validation_results_csv, \"a+\") as csv_file:\n",
    "    df_analysis_results.to_csv(csv_file, header=False, index=False)\n",
    "    \n",
    "df_analysis_results.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Visualización de los resultados"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "phases = ['Recopilación', 'Disneo', 'Implantación', 'Soporte', 'Totales']\n",
    "precisas = df_analysis_results['estimaciones_precisa'].values\n",
    "aceptable = df_analysis_results['ofertas_aceptable'].values\n",
    "errors = df_analysis_results['ofertas_no_aceptable'].values\n",
    "\n",
    "pos = np.arange(len(phases))\n",
    "\n",
    "plt.bar(pos, precisas, width=0.8, label='precisas', color='#00b871', bottom=aceptable+errors)\n",
    "plt.bar(pos, aceptable, width=0.8, label='aceptable', color='#68fc1e', bottom=errors)\n",
    "plt.bar(pos, errors, width=0.8, label='errors', color='red')\n",
    "\n",
    "plt.xticks(pos, phases)\n",
    "plt.ylabel(\"Precisión\")\n",
    "plt.xlabel(\"Phases\")\n",
    "plt.legend(loc=\"upper left\")\n",
    "plt.title(\"Precisión de las estimaciones\")\n",
    "\n",
    "# set the figure size\n",
    "plt.figure(figsize=(15,15))\n",
    "plt.rcParams[\"figure.figsize\"] = [12,10]\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Prediccion EndPoint / Invocación Ad-Hoc"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Definición de oferta y invocación de predicción ad-hoc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "##################################\n",
    "#        OFFER DETAILS           #\n",
    "##################################\n",
    "\n",
    "offer = {\n",
    "  \"greenfield\": 1,          # 1 == TRUE, 0 == FALSE\n",
    "  \"vpc\": 0.5,               # 0 == 0 vpc, 0.5 == 1 vpc, 1 == 2 vpc\n",
    "  \"subnets\": 0.75,          # 0 == 0 subnets, 0.25 == 1 subnets, 0.5 == 2 subnets, 0.75 == 3 subnets, 1 == 4 subnets\n",
    "  \"connectivity\": 1,        # 1 == TRUE, 0 == FALSE \n",
    "  \"peerings\": 0,            # 1 == TRUE, 0 == FALSE \n",
    "  \"directoryservice\": 0,    # 1 == TRUE, 0 == FALSE\n",
    "  \"otherservices\": 1,     # 0 == 0 otherservices, 0.2 == 1 otherservices, 0.4 == 2 otherservices, 0.6 == 3 otherservices, 0.8 == 4 otherservices, 1 == 5 otherservices\n",
    "  \"advsecurity\": 0,         # 1 == TRUE, 0 == FALSE\n",
    "  \"advlogging\": 0,          # 1 == TRUE, 0 == FALSE\n",
    "  \"advmonitoring\": 0,       # 1 == TRUE, 0 == FALSE\n",
    "  \"advbackup\": 0,           # 1 == TRUE, 0 == FALSE\n",
    "  \"vms\": 0.3,               # 0 == 0 vms, 0.1 == 1 vms, 0.2 == 2 vms, 0.3 == 3 vms .... 0.8 == 8 vms, 0.9 == 9 vms, 1 == 10 vms\n",
    "  \"buckets\": 0.5,           # 0 == 0 buckets, 0.5 == 1 buckets, 1 == 2 buckets\n",
    "  \"databases\": 1,           # 0 == 0 BBDD, 0.5 == 1 BBDD, 1 == 2 BBDD\n",
    "  \"elb\": 0,                 # 1 == TRUE, 0 == FALSE \n",
    "  \"autoscripts\": 0,         # 1 == TRUE, 0 == FALSE \n",
    "  \"administered\": 0         # 1 == TRUE, 0 == FALSE \n",
    "}\n",
    "\n",
    "##################################\n",
    "#      OFFER DETAILS END         #\n",
    "##################################\n",
    "\n",
    "\n",
    "##################################\n",
    "# HERE BE DRAGONS!!! \n",
    "# Modify the code below \n",
    "# at your own risk\n",
    "##################################\n",
    "\n",
    "predicition_result = []\n",
    "\n",
    "def make_phase_predictions(phase_number, phase_name, offer_details):\n",
    "    loaded_model = xgb.XGBRegressor()\n",
    "    loaded_model.load_model(f\"models-saved/xgboost/phase_{phase_number}_model.model\")\n",
    "    # dvalidation_phase1 = xgb.DMatrix(phase1_x_validation, label=phase1_y_validation)\n",
    "    phase_prediction = loaded_model.predict(offer_details)\n",
    "    prediction_scaled = get_min_value(phase_prediction[0], phase_number)\n",
    "    predict_result = [phase_number, phase_name, prediction_scaled]\n",
    "    predicition_result.append(predict_result)\n",
    "    return prediction_scaled\n",
    "\n",
    "\n",
    "# phase 1 predicition\n",
    "offer_rows = {'offer': offer}\n",
    "offer_frame = pd.DataFrame.from_dict(offer_rows, orient='index')\n",
    "phase1_predicition = make_phase_predictions(1, \"Recopilacion\", offer_frame)\n",
    "\n",
    "# phase 2 predicition\n",
    "offer['phase1prediction'] = phase1_predicition\n",
    "offer_rows = {'offer': offer}\n",
    "offer_frame = pd.DataFrame.from_dict(offer_rows, orient='index')\n",
    "phase2_predicition = make_phase_predictions(2, \"Diseno\", offer_frame)\n",
    "\n",
    "# phase 3 predicition\n",
    "offer['phase2prediction'] = phase2_predicition\n",
    "offer_rows = {'offer': offer}\n",
    "offer_frame = pd.DataFrame.from_dict(offer_rows, orient='index')\n",
    "phase3_predicition = make_phase_predictions(3, \"Implantacion\", offer_frame)\n",
    "\n",
    "# phase 4 predicition\n",
    "offer['phase3prediction'] = phase3_predicition\n",
    "offer_rows = {'offer': offer}\n",
    "offer_frame = pd.DataFrame.from_dict(offer_rows, orient='index')\n",
    "phase4_predicition = make_phase_predictions(4, \"Soporte\", offer_frame)\n",
    "\n",
    "print(\"Detalles de la oferta:\\n\")\n",
    "offer['phase1prediction'] = predicition_result[0][2]\n",
    "offer['phase2prediction'] = predicition_result[1][2]\n",
    "offer['phase3prediction'] = predicition_result[2][2]\n",
    "offer['phase4prediction'] = predicition_result[3][2]\n",
    "print(json.dumps(offer, indent=4, sort_keys=True))\n",
    "\n",
    "print(\"\\nPrediccion:\\n\")\n",
    "table = PrettyTable(['# Fase','Fase','Jornadas'])\n",
    "table.align[\"# Fase\"] = \"c\"\n",
    "table.align[\"Fase\"] = \"l\"\n",
    "table.align[\"Jornadas\"] = \"c\"\n",
    "for row in predicition_result:\n",
    "    table.add_row(row)\n",
    "\n",
    "table.add_row([5, 'Total', (phase1_predicition + phase2_predicition + phase3_predicition + phase4_predicition)])\n",
    "\n",
    "print(table)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
